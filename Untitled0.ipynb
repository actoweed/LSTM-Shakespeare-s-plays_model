{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "lFbPYgkS6rYo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApdKzBlv6ukC",
        "outputId": "cab047c6-5db8-40e5-9f27-5fa42992854f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"guslovesmath/shakespeare-plays-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9RCt-AG6xj2",
        "outputId": "0cda8323-ce70-414d-bcac-abdcebc40e18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/guslovesmath/shakespeare-plays-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.62M/2.62M [00:00<00:00, 132MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/guslovesmath/shakespeare-plays-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(path, \"shakespeare_plays.csv\")"
      ],
      "metadata": {
        "id": "_tF1N0uu61TI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UNS6hitQ2f3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(file_path)\n",
        "print(\"Sample data:\\n\", data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hxcJkTL7Dwv",
        "outputId": "b2e2d0aa-d4ed-4263-c7c3-36f6c7502604"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data:\n",
            "    Unnamed: 0                  play_name   genre character  act  scene  \\\n",
            "0           0  All's Well That Ends Well  Comedy  Countess    1      1   \n",
            "1           1  All's Well That Ends Well  Comedy   Bertram    1      1   \n",
            "2           2  All's Well That Ends Well  Comedy   Bertram    1      1   \n",
            "3           3  All's Well That Ends Well  Comedy   Bertram    1      1   \n",
            "4           4  All's Well That Ends Well  Comedy     Lafeu    1      1   \n",
            "\n",
            "   sentence                                               text     sex  \n",
            "0         1  In delivering my son from me, I bury a second ...  female  \n",
            "1         2  And I in going, madam, weep o'er my father's d...    male  \n",
            "2         3  anew: but I must attend his majesty's command, to    male  \n",
            "3         4     whom I am now in ward, evermore in subjection.    male  \n",
            "4         5  You shall find of the king a husband, madam; you,    male  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['text'].dropna().tolist()\n",
        "print(f\"Total lines of text: {len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzxwc8P87GZq",
        "outputId": "ce784abe-494b-4a2b-83fb-1aa207d4998a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines of text: 108093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(texts))))\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "vocab_size = len(chars)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGX7L6mx7JIh",
        "outputId": "fcbe65d0-d1d9-4af1-c2d6-0658352c664a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts = [[char_to_idx[char] for char in line] for line in texts]"
      ],
      "metadata": {
        "id": "XSCrnhQU7Ovk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareDataset(Dataset):\n",
        "    def __init__(self, encoded_texts, seq_length):\n",
        "        self.data = []\n",
        "        for line in encoded_texts:\n",
        "            if len(line) > seq_length:\n",
        "                for i in range(len(line) - seq_length):\n",
        "                    self.data.append((line[i:i+seq_length], line[i+1:i+seq_length+1]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.data[idx]\n",
        "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "SEQ_LENGTH = 50\n",
        "dataset = ShakespeareDataset(encoded_texts, SEQ_LENGTH)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "auabdkix7QWA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "        super(TextGenerator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        return (torch.zeros(NUM_LAYERS, batch_size, HIDDEN_DIM, device=device),\n",
        "                torch.zeros(NUM_LAYERS, batch_size, HIDDEN_DIM, device=device))\n"
      ],
      "metadata": {
        "id": "nc9AEbp57U5S"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 4\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "model = TextGenerator(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "52dP3nxw7X1W"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in dataloader:\n",
        "        batch_size = x.size(0)\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        hidden = tuple([h.detach() for h in hidden])\n",
        "        optimizer.zero_grad()\n",
        "        output, hidden = model(x, hidden)\n",
        "        loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / len(dataloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAMmX9e77cEs",
        "outputId": "ec068a2e-345d-40aa-9b06-771215582cdf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.24930177411492566\n",
            "Epoch 2/50, Loss: 0.2488228706469447\n",
            "Epoch 3/50, Loss: 0.2521035800809446\n",
            "Epoch 4/50, Loss: 0.24301806369923656\n",
            "Epoch 5/50, Loss: 0.242953126613768\n",
            "Epoch 6/50, Loss: 0.24384709817837485\n",
            "Epoch 7/50, Loss: 0.2429505254356017\n",
            "Epoch 8/50, Loss: 0.2364598741720182\n",
            "Epoch 9/50, Loss: 0.23523105704080985\n",
            "Epoch 10/50, Loss: 0.2349343531712982\n",
            "Epoch 11/50, Loss: 0.23977079163797155\n",
            "Epoch 12/50, Loss: 0.2368808731159068\n",
            "Epoch 13/50, Loss: 0.23119572735165958\n",
            "Epoch 14/50, Loss: 0.2297775713923555\n",
            "Epoch 15/50, Loss: 0.23107258281352358\n",
            "Epoch 16/50, Loss: 0.22803391719827001\n",
            "Epoch 17/50, Loss: 0.230105095398352\n",
            "Epoch 18/50, Loss: 0.2270642726317696\n",
            "Epoch 19/50, Loss: 0.22856879396283108\n",
            "Epoch 20/50, Loss: 0.22847712345375037\n",
            "Epoch 21/50, Loss: 0.22462937295992183\n",
            "Epoch 22/50, Loss: 0.21635013425387212\n",
            "Epoch 23/50, Loss: 0.21977813750135233\n",
            "Epoch 24/50, Loss: 0.2269503099855429\n",
            "Epoch 25/50, Loss: 0.23173655245615088\n",
            "Epoch 26/50, Loss: 0.21659642337642102\n",
            "Epoch 27/50, Loss: 0.213407725049472\n",
            "Epoch 28/50, Loss: 0.2215791985114909\n",
            "Epoch 29/50, Loss: 0.23506228662795903\n",
            "Epoch 30/50, Loss: 0.20990968981514807\n",
            "Epoch 31/50, Loss: 0.20840531365471596\n",
            "Epoch 32/50, Loss: 0.21297733268197278\n",
            "Epoch 33/50, Loss: 0.23117239824178057\n",
            "Epoch 34/50, Loss: 0.21378573729014544\n",
            "Epoch 35/50, Loss: 0.2086774634648554\n",
            "Epoch 36/50, Loss: 0.21025951974880622\n",
            "Epoch 37/50, Loss: 0.20694295668639012\n",
            "Epoch 38/50, Loss: 0.21774654469875074\n",
            "Epoch 39/50, Loss: 0.21726002849592185\n",
            "Epoch 40/50, Loss: 0.21121415819810785\n",
            "Epoch 41/50, Loss: 0.2074469564864354\n",
            "Epoch 42/50, Loss: 0.20313834667390918\n",
            "Epoch 43/50, Loss: 0.20974920842773426\n",
            "Epoch 44/50, Loss: 0.21315858587159875\n",
            "Epoch 45/50, Loss: 0.2169414242694837\n",
            "Epoch 46/50, Loss: 0.21173669397830963\n",
            "Epoch 47/50, Loss: 0.20492579704671174\n",
            "Epoch 48/50, Loss: 0.19278947726725051\n",
            "Epoch 49/50, Loss: 0.20736995547639658\n",
            "Epoch 50/50, Loss: 0.21187863512809232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_text, length):\n",
        "    model.eval()\n",
        "    hidden = model.init_hidden(1)\n",
        "    input_seq = torch.tensor([char_to_idx[char] for char in start_text], dtype=torch.long).unsqueeze(0).to(device)\n",
        "    generated_text = start_text\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "            char_idx = torch.argmax(output[:, -1, :]).item()\n",
        "            generated_text += idx_to_char[char_idx]\n",
        "            input_seq = torch.tensor([[char_idx]], dtype=torch.long).to(device)\n",
        "\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "h0T3Gu6f8Ee3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_text = input()\n",
        "generated = generate_text(model, start_text, 100)\n",
        "print(\"Generated Text:\")\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3f3-Zhs8Hlq",
        "outputId": "24aeaee9-21ae-44dd-f315-59904365a5a5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap\n",
            "Generated Text:\n",
            "appear you with this ridiculous boldness before my lady? and in these leasure and shipping, and salt I\n"
          ]
        }
      ]
    }
  ]
}